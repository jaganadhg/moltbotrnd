# =============================================================================
# OpenClaw + Ollama — Podman Compose (rootless, security-hardened)
# =============================================================================
# Usage:
#   podman-compose up -d
#   podman-compose logs -f
#   podman-compose down
# =============================================================================

services:
  # ---------------------------------------------------------------------------
  # Ollama — Local LLM inference server
  # ---------------------------------------------------------------------------
  ollama:
    image: docker.io/ollama/ollama:latest
    container_name: openclaw-ollama
    restart: unless-stopped

    # --- Security hardening ---
    security_opt:
      - no-new-privileges:true        # Prevent privilege escalation
    cap_drop:
      - ALL                            # Drop ALL Linux capabilities
    cap_add:
      - NET_BIND_SERVICE               # Required: Ollama needs to bind port 11434

    # --- Resource limits ---
    deploy:
      resources:
        limits:
          memory: 4G                   # Cap memory (adjust for your Phi model size)
          cpus: "4.0"                  # Cap CPU usage
        reservations:
          memory: 1G

    # --- Networking ---
    networks:
      - openclaw-internal
    # No host port exposure — only accessible within the pod network
    # If you need direct Ollama access, uncomment:
    # ports:
    #   - "127.0.0.1:11434:11434"     # Bind to loopback only

    # --- Storage ---
    volumes:
      - ollama_data:/root/.ollama      # Model storage (Ollama default path)
    tmpfs:
      - /tmp:size=512M,noexec,nosuid,nodev # Ephemeral temp with restrictions

    # --- Health check ---
    healthcheck:
      test: ["CMD", "ollama", "list"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

    # --- Environment ---
    environment:
      - OLLAMA_HOST=0.0.0.0:11434      # Listen on all interfaces within container
      - OLLAMA_KEEP_ALIVE=5m           # Keep models loaded for 5 min
      - OLLAMA_NUM_PARALLEL=2          # Limit parallel requests
      - OLLAMA_MAX_LOADED_MODELS=1     # Only one model loaded at a time (save RAM)

  # ---------------------------------------------------------------------------
  # OpenClaw Gateway — AI assistant control plane
  # ---------------------------------------------------------------------------
  openclaw:
    build:
      context: .
      dockerfile: Dockerfile
    image: localhost/openclaw-gateway:local
    container_name: openclaw-gateway
    restart: unless-stopped
    depends_on:
      ollama:
        condition: service_healthy

    # --- Security hardening ---
    security_opt:
      - no-new-privileges:true        # Prevent privilege escalation
    cap_drop:
      - ALL                            # Drop ALL Linux capabilities
    read_only: true                    # Read-only root filesystem

    # --- Resource limits ---
    deploy:
      resources:
        limits:
          memory: 1G
          cpus: "2.0"
        reservations:
          memory: 256M

    # --- Networking ---
    networks:
      - openclaw-internal
    ports:
      - "127.0.0.1:18789:18789"       # Gateway — loopback only (not 0.0.0.0!)

    # --- Storage ---
    volumes:
      # Persistent data (owned by node:1000)
      - openclaw_data:/home/node/.openclaw
      # Config overlay (read-only mount from host)
      - ./config/openclaw.json:/home/node/.openclaw/openclaw.json:ro,Z
      # Workspace for agent files
      - openclaw_workspace:/home/node/.openclaw/workspace
    tmpfs:
      # Writable temp areas (needed because root filesystem is read-only)
      - /tmp:size=256M,noexec,nosuid,nodev
      - /home/node/.openclaw/sessions:size=128M,noexec,nosuid,nodev
      - /home/node/.openclaw/logs:size=64M,noexec,nosuid,nodev

    # --- Environment ---
    environment:
      - NODE_ENV=production
      - HOME=/home/node
      # Gateway authentication (REQUIRED — never run without a token)
      - OPENCLAW_GATEWAY_TOKEN=${OPENCLAW_GATEWAY_TOKEN}
      # Ollama connection (internal network, no host exposure)
      - OLLAMA_HOST=http://ollama:11434

    # --- Startup command ---
    # --bind lan: required so the container port mapping works
    # --allow-unconfigured: permits first-run without full onboard
    command:
      [
        "node", "dist/index.js", "gateway",
        "--bind", "lan",
        "--port", "18789",
        "--allow-unconfigured"
      ]

  # ---------------------------------------------------------------------------
  # OpenClaw CLI — for onboarding and admin commands (run manually)
  # ---------------------------------------------------------------------------
  openclaw-cli:
    build:
      context: .
      dockerfile: Dockerfile
    image: localhost/openclaw-gateway:local
    container_name: openclaw-cli
    profiles:
      - cli                            # Only runs when explicitly invoked
    depends_on:
      - openclaw

    # --- Security hardening ---
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    read_only: true

    # --- Networking ---
    networks:
      - openclaw-internal

    # --- Storage ---
    volumes:
      - openclaw_data:/home/node/.openclaw
      - openclaw_workspace:/home/node/.openclaw/workspace
    tmpfs:
      - /tmp:size=128M,noexec,nosuid,nodev

    # --- Environment ---
    environment:
      - HOME=/home/node
      - TERM=xterm-256color
      - OPENCLAW_GATEWAY_TOKEN=${OPENCLAW_GATEWAY_TOKEN}
      - BROWSER=echo

    # --- Interactive ---
    stdin_open: true
    tty: true
    entrypoint: ["node", "dist/index.js"]

# =============================================================================
# Networks — isolated internal network (no external access for inter-service)
# =============================================================================
networks:
  openclaw-internal:
    driver: bridge
    internal: false                    # Ollama needs outbound to download models initially
    ipam:
      config:
        - subnet: 172.28.0.0/28       # Minimal /28 subnet (14 usable IPs)

# =============================================================================
# Named volumes — persistent data
# =============================================================================
volumes:
  ollama_data:
    driver: local
  openclaw_data:
    driver: local
  openclaw_workspace:
    driver: local